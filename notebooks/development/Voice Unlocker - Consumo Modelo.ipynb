{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "available-westminster",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Testando-Lógica\" data-toc-modified-id=\"Testando-Lógica-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Testando Lógica</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-taste",
   "metadata": {},
   "source": [
    "Ideias:\n",
    "\n",
    "* Criar um diretório específico na pasta do projeto para alocar arquivos mp3 alvos do consumo do modelo\n",
    "* Realizar gravações de áudio usando o app Voice Recorder e automaticamente posicionar os arquivos mp3 no diretório específico criado para leitura e consumo do modelo\n",
    "* Criar script python com algumas regras de verificação de arquivos nesse diretório, como por exemplo:\n",
    "    * Laço infinito de validação de presença de arquivos (ou então um start manual após a gravação)\n",
    "    * Validação da presença de mais de 1 arquivo (warning pro usuário)\n",
    "    * Validação de extensão do arquivo disponibilizado no diretório (necessariamente mp3)\n",
    "* Após a leitura e consumo do modelo, propor a exclusão do arquivo a criação de um histórico de predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "likely-manufacturer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:56:39.313281Z",
     "start_time": "2021-04-05T00:56:38.549321Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import os\n",
    "import librosa\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "informative-floor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:56:39.318000Z",
     "start_time": "2021-04-05T00:56:39.314938Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definindo variáveis de caminho\n",
    "PROJECT_PATH = '/home/paninit/workspaces/voice-unlocker'\n",
    "TARGET_PATH_NAME = 'predictions/audios'\n",
    "TARGET_PATH = os.path.join(PROJECT_PATH, TARGET_PATH_NAME)\n",
    "\n",
    "AUDIO_EXT = '.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-insulation",
   "metadata": {},
   "source": [
    "# Testando Lógica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "logical-nancy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:56:39.327611Z",
     "start_time": "2021-04-05T00:56:39.323201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Criando diretório, caso inexistente\n",
    "if not os.path.isdir(TARGET_PATH):\n",
    "    os.makedirs(TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afraid-scotland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:56:39.336539Z",
     "start_time": "2021-04-05T00:56:39.328875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021_03_11_20_49_08.mp3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando arquivos no diretório\n",
    "os.listdir(TARGET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pacific-trash",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:56:39.343864Z",
     "start_time": "2021-04-05T00:56:39.338389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regra 1 - quantidade de arquivos no diretório\n",
    "valid_files = [file for file in os.listdir(TARGET_PATH) if os.path.splitext(file)[-1] == AUDIO_EXT]\n",
    "qtd_files = len(valid_files)\n",
    "\n",
    "if qtd_files > 1:\n",
    "    print(f'Foram encontrados {qtd_files} arquivos {AUDIO_EXT} no diretório. Necessário validar um áudio por vez.')\n",
    "qtd_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-engine",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spread-center",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:56:39.347574Z",
     "start_time": "2021-04-05T00:56:39.345092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Regra 2 - nenhum arquivo encontrado com a extensão correta\n",
    "if qtd_files == 0:\n",
    "    print(f'Nenhum arquivo {AUDIO_EXT} encontrado no diretório. Verificar extensão do áudio disponibilizado.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-efficiency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T19:41:30.017616Z",
     "start_time": "2021-04-03T19:41:29.988274Z"
    }
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "angry-statistics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:56:39.352596Z",
     "start_time": "2021-04-05T00:56:39.349424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Regra 3 - manter mais recente em caso de múltiplos audios\n",
    "if qtd_files > 1:\n",
    "    ctimes = [os.path.getctime(os.path.join(TARGET_PATH, file)) for file in valid_files]\n",
    "    audio_ctimes = [time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ct)) for ct in ctimes] \n",
    "    print(audio_ctimes)\n",
    "\n",
    "    idx_max_ctime = audio_ctimes.index(max(audio_ctimes))\n",
    "    last_valid_audio = valid_files[idx_max_ctime]\n",
    "    print(last_valid_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-things",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-trigger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T00:55:16.457755Z",
     "start_time": "2021-04-05T00:55:16.446846Z"
    }
   },
   "source": [
    "    # Regra 4 - expurgo dos áudios\n",
    "    for file in os.listdir(TARGET_PATH):\n",
    "        os.remove(os.path.join(TARGET_PATH, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "limited-organic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:11:02.866066Z",
     "start_time": "2021-04-05T01:11:02.851496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021_03_11_20_49_08.mp3']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "infectious-helmet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:10:56.815325Z",
     "start_time": "2021-04-05T01:10:56.596123Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paninit/python-venvs/voice-venv/lib/python3.8/site-packages/librosa/core/audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file = valid_files[0]\n",
    "audio = [librosa.load(os.path.join(TARGET_PATH, audio_file), sr=22050)[0]]\n",
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "identical-miami",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:11:10.418495Z",
     "start_time": "2021-04-05T01:11:10.362855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              signal\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "audio_df = pd.DataFrame([audio])\n",
    "audio_df.columns = ['signal']\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "continued-tobago",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:11:42.619723Z",
     "start_time": "2021-04-05T01:11:42.529169Z"
    },
    "code_folding": [
     5,
     39,
     74,
     126,
     179,
     232,
     292,
     348,
     404,
     500
    ]
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Definindo função para separação de faixas de frequências (BER)\n",
    "def calc_split_freq_bin(spec, split_freq, sr):\n",
    "    \"\"\"\n",
    "    Função responsável por calcular o índice da frequência de separação F\n",
    "    no espectro discreto de frequências\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param spec: espectrograma calculado via STFT [type: ndarray]\n",
    "    :param split_freq: frequência de separação F [type: int]\n",
    "    :param sr: taxa de amostragem do sinal [type: int]\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return idx_split_freq: retorna o índice relacionado ao parâmetro F no espectro discreto [type: int]\n",
    "    :return split_freq_bin: retorna a frequência discreta relacionada ao parâmetro F [type: float]\n",
    "    \"\"\"\n",
    "\n",
    "    # Intervalo de frequências (Nyquist)\n",
    "    f_range = sr / 2\n",
    "\n",
    "    # Intervalo de frequências para cada faixa discreta individual\n",
    "    qtd_freq_bins = spec.shape[0]\n",
    "    f_delta_bin = f_range / qtd_freq_bins\n",
    "\n",
    "    # Calculando índice do parâmetro F nas faixas discretas\n",
    "    idx_split_freq = int(np.floor(split_freq / f_delta_bin))\n",
    "\n",
    "    # Calculando faixa de frequência presente na matriz espectral\n",
    "    freq_bins = np.linspace(0, f_range, qtd_freq_bins)\n",
    "    split_freq_bin = freq_bins[idx_split_freq]\n",
    "\n",
    "    return idx_split_freq, split_freq_bin\n",
    "\n",
    "# Definindo função para o cálculo da Taxa de Energia de Banda (BER)\n",
    "def calc_ber(spec, split_freq, sr):\n",
    "    \"\"\"\n",
    "    Função responsável por calcular a taxa de energia de banda (BER)\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param spec: espectrograma calculado via STFT [type: ndarray]\n",
    "    :param split_freq: frequência de separação F [type: int]\n",
    "    :param sr: taxa de amostragem do sinal [type: int]\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return ber: taxa de energia de banda para cada frame t [type: np.array]\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculando faixa de frequência discreta do parâmetro F\n",
    "    idx_split_freq, split_freq_bin = calc_split_freq_bin(spec, split_freq, sr)\n",
    "    bers = []\n",
    "\n",
    "    # Transformando amplitudes do espectro em potências\n",
    "    power_spec = np.abs(spec) ** 2\n",
    "\n",
    "    # Aplicando transpose para iteração em cada frame\n",
    "    power_spec = power_spec.T\n",
    "\n",
    "    # Calculando somatório para cada frame\n",
    "    for frame in power_spec:\n",
    "        sum_power_low_freq = frame[:idx_split_freq].sum()\n",
    "        sum_power_high_freq = frame[idx_split_freq:].sum()\n",
    "        ber_frame = sum_power_low_freq / sum_power_high_freq\n",
    "        bers.append(ber_frame)\n",
    "\n",
    "    return np.array(bers)\n",
    "\n",
    "# Definindo transformador para envelope de amplitude\n",
    "class AmplitudeEnvelop(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Classe responsável por extrair o envelope de amplitude de sinais de áudio\n",
    "    considerando agregados estatísticos pré definidos.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param frame_size: quantidade de amostrar por enquadramento do sinal [type: int]\n",
    "    :param hop_length: parâmetro de overlapping de quadros do sinal [type: int]\n",
    "    :param signal_col: referência da coluna de armazenamento do sinal na base [type: string, default='signal']\n",
    "    :param feature_aggreg: lista de agregadores estatísticos aplicados após a extração da features\n",
    "        *default=['mean', 'median', 'std', 'var', 'max', 'min']\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return X: base de dados contendo os agregados estatísticos para o envelope de amplitude [type: pd.DataFrame]\n",
    "\n",
    "    Aplicação\n",
    "    ---------\n",
    "    ae_extractor = AmplitudeEnvelop(frame_size=FRAME_SIZE, hop_length=HOP_LENGTH, \n",
    "                                signal_col='signal', feature_aggreg=FEATURE_AGGREG)\n",
    "    X_ae = ae_extractor.fit_transform(X)                          \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, frame_size, hop_length, signal_col='signal',\n",
    "                 feature_aggreg=['mean', 'median', 'std', 'var', 'max', 'min']):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "        self.signal_col = signal_col\n",
    "        self.feature_aggreg = feature_aggreg\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Retornando o envelope de amplitude para cada frame do sinal\n",
    "        X['ae'] = X[self.signal_col].apply(lambda x: np.array([max(x[i:i+self.frame_size]) for i in range(0, len(x), self.hop_length)]))\n",
    "        \n",
    "        # Criando dicionário com agregações do envelope de amplitude de cada sinal\n",
    "        X['aggreg_dict'] = X['ae'].apply(lambda x: pd.DataFrame(x).agg(self.feature_aggreg))\n",
    "        \n",
    "        # Extraindo agregações e enriquecendo dataset\n",
    "        for agg in self.feature_aggreg:\n",
    "            X['ae_' + agg] = X['aggreg_dict'].apply(lambda x: x[0][agg])\n",
    "            \n",
    "        # Eliminando colunas adicionais\n",
    "        X = X.drop(['ae', 'aggreg_dict'], axis=1)\n",
    "            \n",
    "        return X\n",
    "    \n",
    "# Definindo transformador para RMS Energy\n",
    "class RMSEnergy(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Classe responsável por extrair a raíz da energia média quadrática de sinais de áudio\n",
    "    considerando agregados estatísticos pré definidos.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param frame_size: quantidade de amostrar por enquadramento do sinal [type: int]\n",
    "    :param hop_length: parâmetro de overlapping de quadros do sinal [type: int]\n",
    "    :param signal_col: referência da coluna de armazenamento do sinal na base [type: string, default='signal']\n",
    "    :param feature_aggreg: lista de agregadores estatísticos aplicados após a extração da features\n",
    "        *default=['mean', 'median', 'std', 'var', 'max', 'min']\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return X: base de dados contendo os agregados estatísticos para a raíz da energia média quadrática [type: pd.DataFrame]\n",
    "\n",
    "    Aplicação\n",
    "    ---------\n",
    "    rms_extractor = RMSEnergy(frame_size=FRAME_SIZE, hop_length=HOP_LENGTH, \n",
    "                              signal_col='signal', feature_aggreg=FEATURE_AGGREG)\n",
    "    X_rms = rms_extractor.fit_transform(X)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, frame_size, hop_length, signal_col='signal',\n",
    "                 feature_aggreg=['mean', 'median', 'std', 'var', 'max', 'min']):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "        self.signal_col = signal_col\n",
    "        self.feature_aggreg = feature_aggreg\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Extraindo feature para cada sinal\n",
    "        X['rms_engy'] = X[self.signal_col].apply(lambda x: librosa.feature.rms(x, frame_length=self.frame_size, \n",
    "                                                                               hop_length=self.hop_length)[0])\n",
    "        \n",
    "        # Criando dicionário com agregações\n",
    "        X['aggreg_dict'] = X['rms_engy'].apply(lambda x: pd.DataFrame(x).agg(self.feature_aggreg))\n",
    "        \n",
    "        # Extraindo agregações e enriquecendo dataset\n",
    "        for agg in self.feature_aggreg:\n",
    "            X['rms_engy_' + agg] = X['aggreg_dict'].apply(lambda x: x[0][agg])\n",
    "            \n",
    "        # Eliminando colunas adicionais\n",
    "        X = X.drop(['rms_engy', 'aggreg_dict'], axis=1)\n",
    "            \n",
    "        return X\n",
    "    \n",
    "# Definindo transformador para Zero Crossing Rate\n",
    "class ZeroCrossingRate(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Classe responsável por extrair a taxa de cruzamento de zero de sinais de áudio\n",
    "    considerando agregados estatísticos pré definidos.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param frame_size: quantidade de amostrar por enquadramento do sinal [type: int]\n",
    "    :param hop_length: parâmetro de overlapping de quadros do sinal [type: int]\n",
    "    :param signal_col: referência da coluna de armazenamento do sinal na base [type: string, default='signal']\n",
    "    :param feature_aggreg: lista de agregadores estatísticos aplicados após a extração da features\n",
    "        *default=['mean', 'median', 'std', 'var', 'max', 'min']\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return X: base de dados contendo os agregados estatísticos para a taxa de cruzamento de zero [type: pd.DataFrame]\n",
    "\n",
    "    Aplicação\n",
    "    ---------\n",
    "    zcr_extractor = ZeroCrossingRate(frame_size=FRAME_SIZE, hop_length=HOP_LENGTH, \n",
    "                                     signal_col='signal', feature_aggreg=FEATURE_AGGREG)\n",
    "    X_zcr = zcr_extractor.fit_transform(X)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, frame_size, hop_length, signal_col='signal',\n",
    "                 feature_aggreg=['mean', 'median', 'std', 'var', 'max', 'min']):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "        self.signal_col = signal_col\n",
    "        self.feature_aggreg = feature_aggreg\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Extraindo feature para cada sinal\n",
    "        X['zcr'] = X[self.signal_col].apply(lambda x: librosa.feature.zero_crossing_rate(x, frame_length=self.frame_size, \n",
    "                                                                                         hop_length=self.hop_length)[0])\n",
    "        \n",
    "        # Criando dicionário com agregações\n",
    "        X['aggreg_dict'] = X['zcr'].apply(lambda x: pd.DataFrame(x).agg(self.feature_aggreg))\n",
    "        \n",
    "        # Extraindo agregações e enriquecendo dataset\n",
    "        for agg in self.feature_aggreg:\n",
    "            X['zcr_' + agg] = X['aggreg_dict'].apply(lambda x: x[0][agg])\n",
    "            \n",
    "        # Eliminando colunas adicionais\n",
    "        X = X.drop(['zcr', 'aggreg_dict'], axis=1)\n",
    "            \n",
    "        return X\n",
    "\n",
    "# Definindo transformador para BER\n",
    "class BandEnergyRatio(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Classe responsável por extrair a taxa de energia de banda de sinais de áudio\n",
    "    considerando agregados estatísticos pré definidos.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param frame_size: quantidade de amostrar por enquadramento do sinal [type: int]\n",
    "    :param hop_length: parâmetro de overlapping de quadros do sinal [type: int]\n",
    "    :param split_freq: frequência de separação entre altas e baixas frequências [type: int]\n",
    "    :param sr: taxa de amostragem do sinal de áudio [type: int]\n",
    "    :param signal_col: referência da coluna de armazenamento do sinal na base [type: string, default='signal']\n",
    "    :param feature_aggreg: lista de agregadores estatísticos aplicados após a extração da features\n",
    "        *default=['mean', 'median', 'std', 'var', 'max', 'min']\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return X: base de dados contendo os agregados estatísticos para a taxa de energia de banda [type: pd.DataFrame]\n",
    "\n",
    "    Aplicação\n",
    "    ---------\n",
    "    ber_extractor = BandEnergyRatio(frame_size=FRAME_SIZE, hop_length=HOP_LENGTH, \n",
    "                                    signal_col='signal', feature_aggreg=FEATURE_AGGREG)\n",
    "    X_ber = ber_extractor.fit_transform(X)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, frame_size, hop_length, split_freq, sr, signal_col='signal',\n",
    "                 feature_aggreg=['mean', 'median', 'std', 'var', 'max', 'min']):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "        self.split_freq = split_freq\n",
    "        self.sr = sr\n",
    "        self.signal_col = signal_col\n",
    "        self.feature_aggreg = feature_aggreg\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Calculando espectrograma dos sinais\n",
    "        X['spec'] = X[self.signal_col].apply(lambda x: librosa.stft(y=x, n_fft=self.frame_size, \n",
    "                                                                    hop_length=self.hop_length))\n",
    "        \n",
    "        # Calculando BER\n",
    "        X['ber'] = X['spec'].apply(lambda x: calc_ber(spec=x, split_freq=self.split_freq, sr=self.sr))\n",
    "        \n",
    "        # Criando dicionário com agregações\n",
    "        X['aggreg_dict'] = X['ber'].apply(lambda x: pd.DataFrame(x).agg(self.feature_aggreg))\n",
    "        \n",
    "        # Extraindo agregações e enriquecendo dataset\n",
    "        for agg in self.feature_aggreg:\n",
    "            X['ber_' + agg] = X['aggreg_dict'].apply(lambda x: x[0][agg])\n",
    "            \n",
    "        # Eliminando colunas adicionais\n",
    "        X = X.drop(['spec', 'ber', 'aggreg_dict'], axis=1)\n",
    "            \n",
    "        return X\n",
    "    \n",
    "# Definindo transformador para Spectral Centroid\n",
    "class SpectralCentroid(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Classe responsável por extrair o centroide espectral de sinais de áudio\n",
    "    considerando agregados estatísticos pré definidos.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param frame_size: quantidade de amostrar por enquadramento do sinal [type: int]\n",
    "    :param hop_length: parâmetro de overlapping de quadros do sinal [type: int]\n",
    "    :param sr: taxa de amostragem do sinal de áudio [type: int]\n",
    "    :param signal_col: referência da coluna de armazenamento do sinal na base [type: string, default='signal']\n",
    "    :param feature_aggreg: lista de agregadores estatísticos aplicados após a extração da features\n",
    "        *default=['mean', 'median', 'std', 'var', 'max', 'min']\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return X: base de dados contendo os agregados estatísticos para o centroide espectral [type: pd.DataFrame]\n",
    "\n",
    "    Aplicação\n",
    "    ---------\n",
    "    sc_extractor = SpectralCentroid(frame_size=FRAME_SIZE, hop_length=HOP_LENGTH, \n",
    "                                     signal_col='signal', feature_aggreg=FEATURE_AGGREG)\n",
    "    X_sc = sc_extractor.fit_transform(X)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, frame_size, hop_length, sr, signal_col='signal',\n",
    "                 feature_aggreg=['mean', 'median', 'std', 'var', 'max', 'min']):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "        self.sr = sr\n",
    "        self.signal_col = signal_col\n",
    "        self.feature_aggreg = feature_aggreg\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Calculando feature\n",
    "        X['sc'] = X[self.signal_col].apply(lambda x: librosa.feature.spectral_centroid(y=x, sr=self.sr,\n",
    "                                                                                       n_fft=self.frame_size,\n",
    "                                                                                       hop_length=self.hop_length)[0])\n",
    "        \n",
    "        # Criando dicionário com agregações\n",
    "        X['aggreg_dict'] = X['sc'].apply(lambda x: pd.DataFrame(x).agg(self.feature_aggreg))\n",
    "        \n",
    "        # Extraindo agregações e enriquecendo dataset\n",
    "        for agg in self.feature_aggreg:\n",
    "            X['sc_' + agg] = X['aggreg_dict'].apply(lambda x: x[0][agg])\n",
    "            \n",
    "        # Eliminando colunas adicionais\n",
    "        X = X.drop(['sc', 'aggreg_dict'], axis=1)\n",
    "            \n",
    "        return X\n",
    "    \n",
    "# Definindo transformador para BandWidth\n",
    "class BandWidth(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Classe responsável por extrair a largura de banda de sinais de áudio\n",
    "    considerando agregados estatísticos pré definidos.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param frame_size: quantidade de amostrar por enquadramento do sinal [type: int]\n",
    "    :param hop_length: parâmetro de overlapping de quadros do sinal [type: int]\n",
    "    :param sr: taxa de amostragem do sinal de áudio [type: int]\n",
    "    :param signal_col: referência da coluna de armazenamento do sinal na base [type: string, default='signal']\n",
    "    :param feature_aggreg: lista de agregadores estatísticos aplicados após a extração da features\n",
    "        *default=['mean', 'median', 'std', 'var', 'max', 'min']\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return X: base de dados contendo os agregados estatísticos para a largura de banda [type: pd.DataFrame]\n",
    "\n",
    "    Aplicação\n",
    "    ---------\n",
    "    bw_extractor = BandWidth(frame_size=FRAME_SIZE, hop_length=HOP_LENGTH, \n",
    "                             signal_col='signal', feature_aggreg=FEATURE_AGGREG)\n",
    "    X_bw = bw_extractor.fit_transform(X)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, frame_size, hop_length, sr, signal_col='signal',\n",
    "                 feature_aggreg=['mean', 'median', 'std', 'var', 'max', 'min']):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "        self.sr = sr\n",
    "        self.signal_col = signal_col\n",
    "        self.feature_aggreg = feature_aggreg\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Calculando feature\n",
    "        X['bw'] = X[self.signal_col].apply(lambda x: librosa.feature.spectral_bandwidth(y=x, sr=self.sr,\n",
    "                                                                                        n_fft=self.frame_size,\n",
    "                                                                                        hop_length=self.hop_length)[0])\n",
    "        \n",
    "        # Criando dicionário com agregações\n",
    "        X['aggreg_dict'] = X['bw'].apply(lambda x: pd.DataFrame(x).agg(self.feature_aggreg))\n",
    "        \n",
    "        # Extraindo agregações e enriquecendo dataset\n",
    "        for agg in self.feature_aggreg:\n",
    "            X['bw_' + agg] = X['aggreg_dict'].apply(lambda x: x[0][agg])\n",
    "            \n",
    "        # Eliminando colunas adicionais\n",
    "        X = X.drop(['bw', 'aggreg_dict'], axis=1)\n",
    "            \n",
    "        return X\n",
    "    \n",
    "# Definindo transformador para agregação de espectrograma em grupos\n",
    "class GroupSpecAggreg(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Classe responsável por extrair a potência espectral de altas e baixas frequências\n",
    "    de sinais de áudio considerando agregados estatísticos pré definidos.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param frame_size: quantidade de amostrar por enquadramento do sinal [type: int]\n",
    "    :param hop_length: parâmetro de overlapping de quadros do sinal [type: int]\n",
    "    :param sr: taxa de amostragem do sinal de áudio [type: int]\n",
    "    :param split_freq: frequência de separação entre altas e baixas frequências [type: int]\n",
    "    :param freq_cat_aggreg: agregador aplicado no agrupamento das potências [type: int, default='sum']\n",
    "    :param signal_col: referência da coluna de armazenamento do sinal na base [type: string, default='signal']\n",
    "    :param feature_aggreg: lista de agregadores estatísticos aplicados após a extração da features\n",
    "        *default=['mean', 'median', 'std', 'var', 'max', 'min']\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return X: base de dados contendo os agregados estatísticos para a potência espectral agrupada [type: pd.DataFrame]\n",
    "\n",
    "    Aplicação\n",
    "    ---------\n",
    "    spec_extractor = GroupSpecAggreg(frame_size=FRAME_SIZE, hop_length=HOP_LENGTH, \n",
    "                                     signal_col='signal', feature_aggreg=FEATURE_AGGREG)\n",
    "    X_spec = spec_extractor.fit_transform(X)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, frame_size, hop_length, sr, split_freq, freq_cat_aggreg='sum',\n",
    "                 signal_col='signal', feature_aggreg=['mean', 'median', 'std', 'var', 'max', 'min']):\n",
    "        self.frame_size = frame_size\n",
    "        self.hop_length = hop_length\n",
    "        self.sr = sr\n",
    "        self.split_freq = split_freq\n",
    "        self.freq_cat_aggreg = freq_cat_aggreg\n",
    "        self.signal_col = signal_col\n",
    "        self.feature_aggreg = feature_aggreg\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Criando DataFrame vazio e aplicando STFT no sinal\n",
    "        all_spec_agg = pd.DataFrame()\n",
    "        X['spec'] = X[self.signal_col].apply(lambda x: np.abs(librosa.stft(y=x, n_fft=self.frame_size, \n",
    "                                                                           hop_length=self.hop_length))**2)\n",
    "        \n",
    "        idx_split, split_freq = calc_split_freq_bin(X['spec'][0], split_freq=self.split_freq, sr=self.sr)\n",
    "        frequency_bins = np.linspace(0, self.sr/2, 1025)\n",
    "        \n",
    "        # Iterando sobre cada espectrograma de cada sinal\n",
    "        for spec in X['spec']:\n",
    "            # DataFrame intermediário para agregações de cada sinal\n",
    "            signal_spec_agg = pd.DataFrame()\n",
    "            i = 0\n",
    "            \n",
    "            # Separando frequências de acordo com threshold estabelecido\n",
    "            spec_data = pd.DataFrame(spec)\n",
    "            spec_data.reset_index(inplace=True)\n",
    "            spec_data['freq_cat'] = spec_data['index'].apply(lambda x: 'low_freq_pwr' if x <= idx_split else 'high_freq_pwr')\n",
    "            \n",
    "            # Somando potências de baixas e altas frequências\n",
    "            spec_data_sum = spec_data.groupby(by='freq_cat').agg(self.freq_cat_aggreg)\n",
    "            spec_data_sum.drop('index', axis=1, inplace=True)\n",
    "            \n",
    "            # Agregando resultado agregado separado por grupo de frequências\n",
    "            S_aggreg = pd.DataFrame(spec_data_sum).agg(self.feature_aggreg, axis=1)\n",
    "            #print(spec_data_sum)\n",
    "            #print(S_aggreg)\n",
    "\n",
    "            # Iterando sobre cada agregador para gerar um novo DataFrame\n",
    "            for agg in self.feature_aggreg:\n",
    "                S_agg = pd.DataFrame(S_aggreg[agg]).T\n",
    "                S_agg.reset_index(inplace=True, drop=True)\n",
    "                S_agg.columns = [col + '_' + agg for col in S_agg.columns]\n",
    "                \n",
    "                # Unindo agregadores em DataFrame intermediário do sinal\n",
    "                if i == 0:\n",
    "                    signal_spec_agg = S_agg.copy()\n",
    "                else:\n",
    "                    signal_spec_agg = signal_spec_agg.merge(S_agg, left_index=True, right_index=True)\n",
    "                i += 1\n",
    "            \n",
    "            # Empilhando compilado agregado de cada sinal\n",
    "            all_spec_agg = all_spec_agg.append(signal_spec_agg)\n",
    "        \n",
    "        # Enriquecendo dataset com agregações geradas\n",
    "        all_spec_agg.reset_index(inplace=True, drop=True)\n",
    "        X = X.merge(all_spec_agg, left_index=True, right_index=True)\n",
    "        \n",
    "        # Dropando colunas auxiliares\n",
    "        X.drop('spec', axis=1, inplace=True)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "# Definindo transformador para agregação individual de espectrograma\n",
    "class MFCCsAggreg(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Classe responsável por extrair as componentes MFCCs (primeira e segunda derivada)\n",
    "    de sinais de áudio considerando agregados estatísticos pré definidos.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    :param n_mfcc: quantidade de componentes MFCCs extraídas [type: int]\n",
    "    :param order: ordem das derivadas extraídas [type: int, default=0]\n",
    "    :param signal_col: referência da coluna de armazenamento do sinal na base [type: string, default='signal']\n",
    "    :param feature_aggreg: lista de agregadores estatísticos aplicados após a extração da features\n",
    "        *default=['mean', 'median', 'std', 'var', 'max', 'min']\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    :return X: base de dados contendo os agregados estatísticos para as componentes MFCCs [type: pd.DataFrame]\n",
    "\n",
    "    Aplicação\n",
    "    ---------\n",
    "    mfcc_extractor = MFCCsAggreg(frame_size=FRAME_SIZE, hop_length=HOP_LENGTH, \n",
    "                                 signal_col='signal', feature_aggreg=FEATURE_AGGREG)\n",
    "    X_mfcc = mfcc_extractor.fit_transform(X)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_mfcc, order=0, signal_col='signal',\n",
    "                 feature_aggreg=['mean', 'median', 'std', 'var', 'max', 'min']):\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.order = order\n",
    "        self.signal_col = signal_col\n",
    "        self.feature_aggreg = feature_aggreg\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Criando DataFrame vazio e retornando mfccs\n",
    "        all_mfcc_agg = pd.DataFrame()\n",
    "        X['mfcc'] = X[self.signal_col].apply(lambda x: librosa.feature.mfcc(y=x, n_mfcc=self.n_mfcc))\n",
    "        \n",
    "        # Calculando derivadas (se aplicáveis)\n",
    "        if self.order == 1:\n",
    "            X['d1_mfcc'] = X['mfcc'].apply(lambda x: librosa.feature.delta(x, order=1))\n",
    "        \n",
    "        if self.order == 2:\n",
    "            X['d1_mfcc'] = X['mfcc'].apply(lambda x: librosa.feature.delta(x, order=1))\n",
    "            X['d2_mfcc'] = X['mfcc'].apply(lambda x: librosa.feature.delta(x, order=2))\n",
    "        \n",
    "        # Iterando sobre cada conjunto de coeficientes mfccs de cada sinal\n",
    "        if self.order == 0:\n",
    "            for mfcc in X['mfcc']:\n",
    "                # DataFrame intermediário para agregações de cada sinal\n",
    "                signal_mfcc_agg = pd.DataFrame()\n",
    "                i = 0\n",
    "\n",
    "                # Agregando dimensão temporal do espectrograma (eixo 1)\n",
    "                M_aggreg = pd.DataFrame(mfcc).agg(self.feature_aggreg, axis=1)\n",
    "                M_aggreg.index = ['mfcc_c' + str(i) for i in range(1, self.n_mfcc + 1)]\n",
    "\n",
    "                # Iterando sobre cada agregador para gerar um novo DataFrame\n",
    "                for agg in self.feature_aggreg:\n",
    "                    M_agg = pd.DataFrame(M_aggreg[agg]).T\n",
    "                    M_agg.reset_index(inplace=True, drop=True)\n",
    "                    M_agg.columns = [col + '_' + agg for col in M_agg.columns]\n",
    "\n",
    "                    # Unindo agregadores em DataFrame intermediário do sinal\n",
    "                    if i == 0:\n",
    "                        signal_mfcc_agg = M_agg.copy()\n",
    "                    else:\n",
    "                        signal_mfcc_agg = signal_mfcc_agg.merge(M_agg, left_index=True, right_index=True)\n",
    "                    i += 1\n",
    "\n",
    "                # Empilhando compilado agregado de cada sinal\n",
    "                all_mfcc_agg = all_mfcc_agg.append(signal_mfcc_agg)\n",
    "                to_drop = ['mfcc']\n",
    "                \n",
    "        elif self.order == 1:\n",
    "            for mfcc, d1_mfcc in X.loc[:, ['mfcc', 'd1_mfcc']].values:\n",
    "                # DataFrame intermediário para agregações de cada sinal\n",
    "                signal_mfcc_agg = pd.DataFrame()\n",
    "                i = 0\n",
    "\n",
    "                # Agregando dimensão temporal do espectrograma (eixo 1)\n",
    "                M_aggreg_d0 = pd.DataFrame(mfcc).agg(self.feature_aggreg, axis=1)\n",
    "                M_aggreg_d0.index = ['mfcc_c' + str(i) for i in range(1, self.n_mfcc + 1)]\n",
    "                \n",
    "                M_aggreg_d1 = pd.DataFrame(d1_mfcc).agg(self.feature_aggreg, axis=1)\n",
    "                M_aggreg_d1.index = ['d1_mfcc_c' + str(i) for i in range(1, self.n_mfcc + 1)]\n",
    "\n",
    "                # Iterando sobre cada agregador para gerar um novo DataFrame\n",
    "                for agg in self.feature_aggreg:\n",
    "                    M_agg_d0 = pd.DataFrame(M_aggreg_d0[agg]).T\n",
    "                    M_agg_d0.reset_index(inplace=True, drop=True)\n",
    "                    M_agg_d0.columns = [col + '_' + agg for col in M_agg_d0.columns]\n",
    "                                       \n",
    "                    M_agg_d1 = pd.DataFrame(M_aggreg_d1[agg]).T\n",
    "                    M_agg_d1.reset_index(inplace=True, drop=True)\n",
    "                    M_agg_d1.columns = [col + '_' + agg for col in M_agg_d1.columns]\n",
    "                    \n",
    "                    M_agg = M_agg_d0.merge(M_agg_d1, left_index=True, right_index=True)\n",
    "\n",
    "                    # Unindo agregadores em DataFrame intermediário do sinal\n",
    "                    if i == 0:\n",
    "                        signal_mfcc_agg = M_agg.copy()\n",
    "                    else:\n",
    "                        signal_mfcc_agg = signal_mfcc_agg.merge(M_agg, left_index=True, right_index=True)\n",
    "                    i += 1\n",
    "\n",
    "                # Empilhando compilado agregado de cada sinal\n",
    "                all_mfcc_agg = all_mfcc_agg.append(signal_mfcc_agg)\n",
    "                to_drop = ['mfcc', 'd1_mfcc']\n",
    "                \n",
    "        elif self.order == 2:\n",
    "            for mfcc, d1_mfcc, d2_mfcc in X.loc[:, ['mfcc', 'd1_mfcc', 'd2_mfcc']].values:\n",
    "                # DataFrame intermediário para agregações de cada sinal\n",
    "                signal_mfcc_agg = pd.DataFrame()\n",
    "                i = 0\n",
    "\n",
    "                # Agregando dimensão temporal do espectrograma (eixo 1)\n",
    "                M_aggreg_d0 = pd.DataFrame(mfcc).agg(self.feature_aggreg, axis=1)\n",
    "                M_aggreg_d0.index = ['mfcc_c' + str(i) for i in range(1, self.n_mfcc + 1)]\n",
    "                \n",
    "                M_aggreg_d1 = pd.DataFrame(d1_mfcc).agg(self.feature_aggreg, axis=1)\n",
    "                M_aggreg_d1.index = ['d1_mfcc_c' + str(i) for i in range(1, self.n_mfcc + 1)]\n",
    "                \n",
    "                M_aggreg_d2 = pd.DataFrame(d2_mfcc).agg(self.feature_aggreg, axis=1)\n",
    "                M_aggreg_d2.index = ['d2_mfcc_c' + str(i) for i in range(1, self.n_mfcc + 1)]\n",
    "\n",
    "                # Iterando sobre cada agregador para gerar um novo DataFrame\n",
    "                for agg in self.feature_aggreg:\n",
    "                    M_agg_d0 = pd.DataFrame(M_aggreg_d0[agg]).T\n",
    "                    M_agg_d0.reset_index(inplace=True, drop=True)\n",
    "                    M_agg_d0.columns = [col + '_' + agg for col in M_agg_d0.columns]\n",
    "                                       \n",
    "                    M_agg_d1 = pd.DataFrame(M_aggreg_d1[agg]).T\n",
    "                    M_agg_d1.reset_index(inplace=True, drop=True)\n",
    "                    M_agg_d1.columns = [col + '_' + agg for col in M_agg_d1.columns]\n",
    "                    \n",
    "                    M_agg_d2 = pd.DataFrame(M_aggreg_d2[agg]).T\n",
    "                    M_agg_d2.reset_index(inplace=True, drop=True)\n",
    "                    M_agg_d2.columns = [col + '_' + agg for col in M_agg_d2.columns]\n",
    "                    \n",
    "                    M_agg = M_agg_d0.merge(M_agg_d1, left_index=True, right_index=True)\n",
    "                    M_agg = M_agg.merge(M_agg_d2, left_index=True, right_index=True)\n",
    "\n",
    "                    # Unindo agregadores em DataFrame intermediário do sinal\n",
    "                    if i == 0:\n",
    "                        signal_mfcc_agg = M_agg.copy()\n",
    "                    else:\n",
    "                        signal_mfcc_agg = signal_mfcc_agg.merge(M_agg, left_index=True, right_index=True)\n",
    "                    i += 1\n",
    "\n",
    "                # Empilhando compilado agregado de cada sinal\n",
    "                all_mfcc_agg = all_mfcc_agg.append(signal_mfcc_agg)\n",
    "                to_drop = ['mfcc', 'd1_mfcc', 'd2_mfcc']\n",
    "        \n",
    "        # Enriquecendo dataset com agregações geradas\n",
    "        all_mfcc_agg.reset_index(inplace=True, drop=True)\n",
    "        X = X.merge(all_mfcc_agg, left_index=True, right_index=True)\n",
    "        \n",
    "        # Dropando colunas auxiliares\n",
    "        X.drop(to_drop, axis=1, inplace=True)\n",
    "        \n",
    "        return X\n",
    "\n",
    "\n",
    "# Definindo variáveis para extração de artefatos\n",
    "PIPELINE_PATH = os.path.join(PROJECT_PATH, 'pipelines')\n",
    "PIPELINE_NAME = 'audio_fe_pipeline.pkl'\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'model')\n",
    "MODEL_NAME = 'lgbm_clf.pkl'\n",
    "\n",
    "# Lendo pipeline de preparação e modelo treinado\n",
    "pipeline = joblib.load(os.path.join(PIPELINE_PATH, PIPELINE_NAME))\n",
    "model = joblib.load(os.path.join(MODEL_PATH, MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "liable-motor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:11:43.528347Z",
     "start_time": "2021-04-05T01:11:43.140262Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_prep = pipeline.fit_transform(audio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "alien-spelling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:11:46.307689Z",
     "start_time": "2021-04-05T01:11:46.264137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "      <th>ae_mean</th>\n",
       "      <th>ae_median</th>\n",
       "      <th>ae_std</th>\n",
       "      <th>ae_var</th>\n",
       "      <th>ae_max</th>\n",
       "      <th>ae_kurtosis</th>\n",
       "      <th>ae_skew</th>\n",
       "      <th>rms_engy_mean</th>\n",
       "      <th>rms_engy_median</th>\n",
       "      <th>...</th>\n",
       "      <th>d2_mfcc_c4_skew</th>\n",
       "      <th>d2_mfcc_c5_skew</th>\n",
       "      <th>d2_mfcc_c6_skew</th>\n",
       "      <th>d2_mfcc_c7_skew</th>\n",
       "      <th>d2_mfcc_c8_skew</th>\n",
       "      <th>d2_mfcc_c9_skew</th>\n",
       "      <th>d2_mfcc_c10_skew</th>\n",
       "      <th>d2_mfcc_c11_skew</th>\n",
       "      <th>d2_mfcc_c12_skew</th>\n",
       "      <th>d2_mfcc_c13_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.158322</td>\n",
       "      <td>0.13208</td>\n",
       "      <td>0.134365</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.581573</td>\n",
       "      <td>-0.135131</td>\n",
       "      <td>0.750086</td>\n",
       "      <td>0.053612</td>\n",
       "      <td>0.039259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025019</td>\n",
       "      <td>0.290705</td>\n",
       "      <td>0.130415</td>\n",
       "      <td>0.22064</td>\n",
       "      <td>-0.157529</td>\n",
       "      <td>0.101512</td>\n",
       "      <td>-0.049428</td>\n",
       "      <td>-0.125009</td>\n",
       "      <td>-0.06242</td>\n",
       "      <td>-0.131471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              signal   ae_mean  ae_median  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0.158322    0.13208   \n",
       "\n",
       "     ae_std    ae_var    ae_max  ae_kurtosis   ae_skew  rms_engy_mean  \\\n",
       "0  0.134365  0.018054  0.581573    -0.135131  0.750086       0.053612   \n",
       "\n",
       "   rms_engy_median  ...  d2_mfcc_c4_skew  d2_mfcc_c5_skew  d2_mfcc_c6_skew  \\\n",
       "0         0.039259  ...         0.025019         0.290705         0.130415   \n",
       "\n",
       "   d2_mfcc_c7_skew  d2_mfcc_c8_skew  d2_mfcc_c9_skew  d2_mfcc_c10_skew  \\\n",
       "0          0.22064        -0.157529         0.101512         -0.049428   \n",
       "\n",
       "   d2_mfcc_c11_skew  d2_mfcc_c12_skew  d2_mfcc_c13_skew  \n",
       "0         -0.125009          -0.06242         -0.131471  \n",
       "\n",
       "[1 rows x 330 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "starting-neutral",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-05T01:32:17.922202Z",
     "start_time": "2021-04-05T01:32:17.907502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_03_11_20_49_08.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                audio_file\n",
       "0  2021_03_11_20_49_08.mp3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_audios = pd.DataFrame()\n",
    "df_audios['audio_file'] = [audio_file]\n",
    "df_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-mustang",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
